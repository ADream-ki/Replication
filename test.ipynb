{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0926 14:20:52.966668  6597 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 6.1, Driver API Version: 12.0, Runtime API Version: 11.8\n",
      "W0926 14:20:52.972939  6597 dynamic_loader.cc:314] The third-party dynamic library (libcudnn.so) that Paddle depends on is not configured correctly. (error code is /usr/local/cuda/lib64/libcudnn.so: cannot open shared object file: No such file or directory)\n",
      "  Suggestions:\n",
      "  1. Check if the third-party dynamic library (e.g. CUDA, CUDNN) is installed correctly and its version is matched with paddlepaddle you installed.\n",
      "  2. Configure third-party dynamic library environment variables as follows:\n",
      "  - Linux: set LD_LIBRARY_PATH by `export LD_LIBRARY_PATH=...`\n",
      "  - Windows: set PATH by `set PATH=XXX;\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "(PreconditionNotMet) Cannot load cudnn shared library. Cannot invoke method cudnnGetVersion.\n  [Hint: cudnn_dso_handle should not be null.] (at /paddle/paddle/phi/backends/dynload/cudnn.cc:64)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 8\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpaddle\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# x = paddle.to_tensor([[-114.6, 10.9, 1.1], [-0.304, 38.07, 69.38], [-0.45, -0.17, 62]])\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# tau = paddle.to_tensor([1.55, 1.94, 3.0])\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# y = paddle.to_tensor([[-114.6, 10.9, 1.1], [-0.304, 38.07, 69.38], [-0.45, -0.17, 62]])\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# result = x.ormqr(tau, y, transpose=True)\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# print(result)\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m x\u001b[38;5;241m=\u001b[39m\u001b[43mpaddle\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mempty\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m7\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28mprint\u001b[39m(x\u001b[38;5;241m.\u001b[39mstrids)\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28mprint\u001b[39m(x\u001b[38;5;241m.\u001b[39mshape)\n",
      "File \u001b[0;32m~/miniconda3/envs/paddleAnd310/lib/python3.10/site-packages/paddle/tensor/creation.py:2115\u001b[0m, in \u001b[0;36mempty\u001b[0;34m(shape, dtype, name)\u001b[0m\n\u001b[1;32m   2113\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m in_dynamic_or_pir_mode():\n\u001b[1;32m   2114\u001b[0m     shape \u001b[38;5;241m=\u001b[39m paddle\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mconvert_shape_to_list(shape)\n\u001b[0;32m-> 2115\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[43m_C_ops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mempty\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2116\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert_np_dtype_to_dtype_\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_current_expected_place\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2117\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2118\u001b[0m     out\u001b[38;5;241m.\u001b[39mstop_gradient \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m   2119\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "\u001b[0;31mRuntimeError\u001b[0m: (PreconditionNotMet) Cannot load cudnn shared library. Cannot invoke method cudnnGetVersion.\n  [Hint: cudnn_dso_handle should not be null.] (at /paddle/paddle/phi/backends/dynload/cudnn.cc:64)\n"
     ]
    }
   ],
   "source": [
    "import paddle\n",
    "# x = paddle.to_tensor([[-114.6, 10.9, 1.1], [-0.304, 38.07, 69.38], [-0.45, -0.17, 62]])\n",
    "# tau = paddle.to_tensor([1.55, 1.94, 3.0])\n",
    "# y = paddle.to_tensor([[-114.6, 10.9, 1.1], [-0.304, 38.07, 69.38], [-0.45, -0.17, 62]])\n",
    "# result = x.ormqr(tau, y, transpose=True)\n",
    "# print(result)\n",
    "\n",
    "x=paddle.empty((2, 3, 5, 7))\n",
    "print(x.strids)\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 1, 2, 3)\n",
      "(105, 35, 7, 1)\n",
      "torch.Size([2, 3, 5, 7])\n",
      "(105, 1, 21, 3)\n",
      "(0, 2, 3, 1)\n",
      "torch.Size([2, 3, 5, 7])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "# b = 4\n",
    "# batch_size = 3\n",
    "# n = 3\n",
    "# A = torch.randn(batch_size, n, n)\n",
    "\n",
    "# # 计算每个批次矩阵的逆以及额外信息\n",
    "# A_invs, infos = torch.linalg.inv_ex(A, check_errors=True)\n",
    "# print(infos)\n",
    "x=torch.empty((2, 3, 5, 7))\n",
    "print(x.dim_order())\n",
    "print(x.stride())\n",
    "print(x.size())\n",
    "x=torch.empty((2, 3, 5, 7), memory_format=torch.channels_last)\n",
    "print(x.stride())\n",
    "print(x.dim_order())\n",
    "print(x.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(shape=[512], dtype=float32, place=Place(cpu), stop_gradient=True,\n",
      "       [0.        , 0.00391389, 0.00782779, 0.01174168, 0.01565558, 0.01956947,\n",
      "        0.02348337, 0.02739726, 0.03131115, 0.03522505, 0.03913894, 0.04305284,\n",
      "        0.04696673, 0.05088063, 0.05479452, 0.05870841, 0.06262231, 0.06653620,\n",
      "        0.07045010, 0.07436399, 0.07827789, 0.08219178, 0.08610567, 0.09001957,\n",
      "        0.09393346, 0.09784736, 0.10176125, 0.10567515, 0.10958904, 0.11350293,\n",
      "        0.11741683, 0.12133072, 0.12524462, 0.12915851, 0.13307241, 0.13698630,\n",
      "        0.14090019, 0.14481409, 0.14872798, 0.15264188, 0.15655577, 0.16046967,\n",
      "        0.16438356, 0.16829745, 0.17221135, 0.17612524, 0.18003914, 0.18395303,\n",
      "        0.18786693, 0.19178082, 0.19569471, 0.19960861, 0.20352250, 0.20743640,\n",
      "        0.21135029, 0.21526419, 0.21917808, 0.22309197, 0.22700587, 0.23091976,\n",
      "        0.23483366, 0.23874755, 0.24266145, 0.24657534, 0.25048923, 0.25440314,\n",
      "        0.25831702, 0.26223093, 0.26614481, 0.27005872, 0.27397260, 0.27788651,\n",
      "        0.28180039, 0.28571430, 0.28962818, 0.29354209, 0.29745597, 0.30136988,\n",
      "        0.30528376, 0.30919766, 0.31311154, 0.31702545, 0.32093933, 0.32485324,\n",
      "        0.32876712, 0.33268103, 0.33659491, 0.34050882, 0.34442270, 0.34833661,\n",
      "        0.35225049, 0.35616440, 0.36007828, 0.36399218, 0.36790606, 0.37181997,\n",
      "        0.37573385, 0.37964776, 0.38356164, 0.38747555, 0.39138943, 0.39530334,\n",
      "        0.39921722, 0.40313113, 0.40704501, 0.41095892, 0.41487280, 0.41878670,\n",
      "        0.42270058, 0.42661449, 0.43052837, 0.43444228, 0.43835616, 0.44227007,\n",
      "        0.44618395, 0.45009786, 0.45401174, 0.45792565, 0.46183953, 0.46575344,\n",
      "        0.46966732, 0.47358122, 0.47749510, 0.48140901, 0.48532289, 0.48923680,\n",
      "        0.49315068, 0.49706459, 0.50097847, 0.50489235, 0.50880629, 0.51272017,\n",
      "        0.51663405, 0.52054793, 0.52446187, 0.52837574, 0.53228962, 0.53620350,\n",
      "        0.54011744, 0.54403132, 0.54794520, 0.55185908, 0.55577302, 0.55968690,\n",
      "        0.56360078, 0.56751466, 0.57142860, 0.57534248, 0.57925636, 0.58317024,\n",
      "        0.58708417, 0.59099805, 0.59491193, 0.59882581, 0.60273975, 0.60665363,\n",
      "        0.61056751, 0.61448139, 0.61839533, 0.62230921, 0.62622309, 0.63013697,\n",
      "        0.63405091, 0.63796479, 0.64187866, 0.64579254, 0.64970648, 0.65362036,\n",
      "        0.65753424, 0.66144812, 0.66536206, 0.66927594, 0.67318982, 0.67710370,\n",
      "        0.68101764, 0.68493152, 0.68884540, 0.69275928, 0.69667321, 0.70058709,\n",
      "        0.70450097, 0.70841485, 0.71232879, 0.71624267, 0.72015655, 0.72407043,\n",
      "        0.72798437, 0.73189825, 0.73581213, 0.73972601, 0.74363995, 0.74755383,\n",
      "        0.75146770, 0.75538158, 0.75929552, 0.76320940, 0.76712328, 0.77103716,\n",
      "        0.77495110, 0.77886498, 0.78277886, 0.78669274, 0.79060668, 0.79452056,\n",
      "        0.79843444, 0.80234832, 0.80626225, 0.81017613, 0.81409001, 0.81800389,\n",
      "        0.82191783, 0.82583171, 0.82974559, 0.83365947, 0.83757341, 0.84148729,\n",
      "        0.84540117, 0.84931505, 0.85322899, 0.85714287, 0.86105675, 0.86497062,\n",
      "        0.86888456, 0.87279844, 0.87671232, 0.88062620, 0.88454014, 0.88845402,\n",
      "        0.89236790, 0.89628178, 0.90019572, 0.90410960, 0.90802348, 0.91193736,\n",
      "        0.91585129, 0.91976517, 0.92367905, 0.92759293, 0.93150687, 0.93542075,\n",
      "        0.93933463, 0.94324851, 0.94716245, 0.95107633, 0.95499021, 0.95890409,\n",
      "        0.96281803, 0.96673191, 0.97064579, 0.97455966, 0.97847360, 0.98238748,\n",
      "        0.98630136, 0.99021524, 0.99412918, 0.99804306, 1.00195694, 1.00587082,\n",
      "        1.00978470, 1.01369858, 1.01761258, 1.02152646, 1.02544034, 1.02935421,\n",
      "        1.03326809, 1.03718197, 1.04109585, 1.04500973, 1.04892373, 1.05283761,\n",
      "        1.05675149, 1.06066537, 1.06457925, 1.06849313, 1.07240701, 1.07632089,\n",
      "        1.08023489, 1.08414876, 1.08806264, 1.09197652, 1.09589040, 1.09980428,\n",
      "        1.10371816, 1.10763204, 1.11154604, 1.11545992, 1.11937380, 1.12328768,\n",
      "        1.12720156, 1.13111544, 1.13502932, 1.13894320, 1.14285719, 1.14677107,\n",
      "        1.15068495, 1.15459883, 1.15851271, 1.16242659, 1.16634047, 1.17025435,\n",
      "        1.17416835, 1.17808223, 1.18199611, 1.18590999, 1.18982387, 1.19373775,\n",
      "        1.19765162, 1.20156550, 1.20547950, 1.20939338, 1.21330726, 1.21722114,\n",
      "        1.22113502, 1.22504890, 1.22896278, 1.23287666, 1.23679066, 1.24070454,\n",
      "        1.24461842, 1.24853230, 1.25244617, 1.25636005, 1.26027393, 1.26418781,\n",
      "        1.26810181, 1.27201569, 1.27592957, 1.27984345, 1.28375733, 1.28767121,\n",
      "        1.29158509, 1.29549897, 1.29941297, 1.30332685, 1.30724072, 1.31115460,\n",
      "        1.31506848, 1.31898236, 1.32289624, 1.32681012, 1.33072412, 1.33463800,\n",
      "        1.33855188, 1.34246576, 1.34637964, 1.35029352, 1.35420740, 1.35812128,\n",
      "        1.36203527, 1.36594915, 1.36986303, 1.37377691, 1.37769079, 1.38160467,\n",
      "        1.38551855, 1.38943243, 1.39334643, 1.39726031, 1.40117419, 1.40508807,\n",
      "        1.40900195, 1.41291583, 1.41682971, 1.42074358, 1.42465758, 1.42857146,\n",
      "        1.43248534, 1.43639922, 1.44031310, 1.44422698, 1.44814086, 1.45205474,\n",
      "        1.45596874, 1.45988262, 1.46379650, 1.46771038, 1.47162426, 1.47553813,\n",
      "        1.47945201, 1.48336589, 1.48727989, 1.49119377, 1.49510765, 1.49902153,\n",
      "        1.50293541, 1.50684929, 1.51076317, 1.51467705, 1.51859105, 1.52250493,\n",
      "        1.52641881, 1.53033268, 1.53424656, 1.53816044, 1.54207432, 1.54598820,\n",
      "        1.54990220, 1.55381608, 1.55772996, 1.56164384, 1.56555772, 1.56947160,\n",
      "        1.57338548, 1.57729936, 1.58121336, 1.58512723, 1.58904111, 1.59295499,\n",
      "        1.59686887, 1.60078275, 1.60469663, 1.60861051, 1.61252451, 1.61643839,\n",
      "        1.62035227, 1.62426615, 1.62818003, 1.63209391, 1.63600779, 1.63992167,\n",
      "        1.64383566, 1.64774954, 1.65166342, 1.65557730, 1.65949118, 1.66340506,\n",
      "        1.66731894, 1.67123282, 1.67514682, 1.67906070, 1.68297458, 1.68688846,\n",
      "        1.69080234, 1.69471622, 1.69863009, 1.70254397, 1.70645797, 1.71037185,\n",
      "        1.71428573, 1.71819961, 1.72211349, 1.72602737, 1.72994125, 1.73385513,\n",
      "        1.73776913, 1.74168301, 1.74559689, 1.74951077, 1.75342464, 1.75733852,\n",
      "        1.76125240, 1.76516628, 1.76908028, 1.77299416, 1.77690804, 1.78082192,\n",
      "        1.78473580, 1.78864968, 1.79256356, 1.79647744, 1.80039144, 1.80430532,\n",
      "        1.80821919, 1.81213307, 1.81604695, 1.81996083, 1.82387471, 1.82778859,\n",
      "        1.83170259, 1.83561647, 1.83953035, 1.84344423, 1.84735811, 1.85127199,\n",
      "        1.85518587, 1.85909975, 1.86301374, 1.86692762, 1.87084150, 1.87475538,\n",
      "        1.87866926, 1.88258314, 1.88649702, 1.89041090, 1.89432490, 1.89823878,\n",
      "        1.90215266, 1.90606654, 1.90998042, 1.91389430, 1.91780818, 1.92172205,\n",
      "        1.92563605, 1.92954993, 1.93346381, 1.93737769, 1.94129157, 1.94520545,\n",
      "        1.94911933, 1.95303321, 1.95694721, 1.96086109, 1.96477497, 1.96868885,\n",
      "        1.97260273, 1.97651660, 1.98043048, 1.98434436, 1.98825836, 1.99217224,\n",
      "        1.99608612, 2.        ])\n",
      "Tensor(shape=[512], dtype=float32, place=Place(cpu), stop_gradient=True,\n",
      "       [0.        , 0.00391389, 0.00782779, 0.01174168, 0.01565558, 0.01956947,\n",
      "        0.02348337, 0.02739726, 0.03131115, 0.03522505, 0.03913894, 0.04305284,\n",
      "        0.04696673, 0.05088063, 0.05479452, 0.05870841, 0.06262231, 0.06653620,\n",
      "        0.07045010, 0.07436399, 0.07827789, 0.08219178, 0.08610567, 0.09001957,\n",
      "        0.09393346, 0.09784736, 0.10176125, 0.10567515, 0.10958904, 0.11350293,\n",
      "        0.11741683, 0.12133072, 0.12524462, 0.12915851, 0.13307241, 0.13698630,\n",
      "        0.14090019, 0.14481409, 0.14872798, 0.15264188, 0.15655577, 0.16046967,\n",
      "        0.16438356, 0.16829745, 0.17221135, 0.17612524, 0.18003914, 0.18395303,\n",
      "        0.18786693, 0.19178082, 0.19569471, 0.19960861, 0.20352250, 0.20743640,\n",
      "        0.21135029, 0.21526419, 0.21917808, 0.22309197, 0.22700587, 0.23091976,\n",
      "        0.23483366, 0.23874755, 0.24266145, 0.24657534, 0.25048923, 0.25440314,\n",
      "        0.25831702, 0.26223093, 0.26614481, 0.27005872, 0.27397260, 0.27788651,\n",
      "        0.28180039, 0.28571430, 0.28962818, 0.29354209, 0.29745597, 0.30136988,\n",
      "        0.30528376, 0.30919766, 0.31311154, 0.31702545, 0.32093933, 0.32485324,\n",
      "        0.32876712, 0.33268103, 0.33659491, 0.34050882, 0.34442270, 0.34833661,\n",
      "        0.35225049, 0.35616440, 0.36007828, 0.36399218, 0.36790606, 0.37181997,\n",
      "        0.37573385, 0.37964776, 0.38356164, 0.38747555, 0.39138943, 0.39530334,\n",
      "        0.39921722, 0.40313113, 0.40704501, 0.41095892, 0.41487280, 0.41878670,\n",
      "        0.42270058, 0.42661449, 0.43052837, 0.43444228, 0.43835616, 0.44227007,\n",
      "        0.44618395, 0.45009786, 0.45401174, 0.45792565, 0.46183953, 0.46575344,\n",
      "        0.46966732, 0.47358122, 0.47749510, 0.48140901, 0.48532289, 0.48923680,\n",
      "        0.49315068, 0.49706459, 0.50097847, 0.50489235, 0.50880629, 0.51272017,\n",
      "        0.51663405, 0.52054793, 0.52446187, 0.52837574, 0.53228962, 0.53620350,\n",
      "        0.54011744, 0.54403132, 0.54794520, 0.55185908, 0.55577302, 0.55968690,\n",
      "        0.56360078, 0.56751466, 0.57142860, 0.57534248, 0.57925636, 0.58317024,\n",
      "        0.58708417, 0.59099805, 0.59491193, 0.59882581, 0.60273975, 0.60665363,\n",
      "        0.61056751, 0.61448139, 0.61839533, 0.62230921, 0.62622309, 0.63013697,\n",
      "        0.63405091, 0.63796479, 0.64187866, 0.64579254, 0.64970648, 0.65362036,\n",
      "        0.65753424, 0.66144812, 0.66536206, 0.66927594, 0.67318982, 0.67710370,\n",
      "        0.68101764, 0.68493152, 0.68884540, 0.69275928, 0.69667321, 0.70058709,\n",
      "        0.70450097, 0.70841485, 0.71232879, 0.71624267, 0.72015655, 0.72407043,\n",
      "        0.72798437, 0.73189825, 0.73581213, 0.73972601, 0.74363995, 0.74755383,\n",
      "        0.75146770, 0.75538158, 0.75929552, 0.76320940, 0.76712328, 0.77103716,\n",
      "        0.77495110, 0.77886498, 0.78277886, 0.78669274, 0.79060668, 0.79452056,\n",
      "        0.79843444, 0.80234832, 0.80626225, 0.81017613, 0.81409001, 0.81800389,\n",
      "        0.82191783, 0.82583171, 0.82974559, 0.83365947, 0.83757341, 0.84148729,\n",
      "        0.84540117, 0.84931505, 0.85322899, 0.85714287, 0.86105675, 0.86497062,\n",
      "        0.86888456, 0.87279844, 0.87671232, 0.88062620, 0.88454014, 0.88845402,\n",
      "        0.89236790, 0.89628178, 0.90019572, 0.90410960, 0.90802348, 0.91193736,\n",
      "        0.91585129, 0.91976517, 0.92367905, 0.92759293, 0.93150687, 0.93542075,\n",
      "        0.93933463, 0.94324851, 0.94716245, 0.95107633, 0.95499021, 0.95890409,\n",
      "        0.96281803, 0.96673191, 0.97064579, 0.97455966, 0.97847360, 0.98238748,\n",
      "        0.98630136, 0.99021524, 0.99412918, 0.99804306, 0.99804306, 0.99412918,\n",
      "        0.99021530, 0.98630142, 0.98238742, 0.97847354, 0.97455966, 0.97064579,\n",
      "        0.96673191, 0.96281803, 0.95890415, 0.95499027, 0.95107627, 0.94716239,\n",
      "        0.94324851, 0.93933463, 0.93542075, 0.93150687, 0.92759299, 0.92367911,\n",
      "        0.91976511, 0.91585124, 0.91193736, 0.90802348, 0.90410960, 0.90019572,\n",
      "        0.89628184, 0.89236796, 0.88845396, 0.88454008, 0.88062620, 0.87671232,\n",
      "        0.87279844, 0.86888456, 0.86497068, 0.86105680, 0.85714281, 0.85322893,\n",
      "        0.84931505, 0.84540117, 0.84148729, 0.83757341, 0.83365953, 0.82974565,\n",
      "        0.82583165, 0.82191777, 0.81800389, 0.81409001, 0.81017613, 0.80626225,\n",
      "        0.80234838, 0.79843450, 0.79452050, 0.79060662, 0.78669274, 0.78277886,\n",
      "        0.77886498, 0.77495110, 0.77103722, 0.76712334, 0.76320934, 0.75929546,\n",
      "        0.75538158, 0.75146770, 0.74755383, 0.74363995, 0.73972607, 0.73581219,\n",
      "        0.73189819, 0.72798431, 0.72407043, 0.72015655, 0.71624267, 0.71232879,\n",
      "        0.70841491, 0.70450103, 0.70058703, 0.69667315, 0.69275928, 0.68884540,\n",
      "        0.68493152, 0.68101764, 0.67710376, 0.67318988, 0.66927588, 0.66536200,\n",
      "        0.66144812, 0.65753424, 0.65362036, 0.64970648, 0.64579260, 0.64187872,\n",
      "        0.63796473, 0.63405085, 0.63013697, 0.62622309, 0.62230921, 0.61839533,\n",
      "        0.61448145, 0.61056757, 0.60665357, 0.60273969, 0.59882581, 0.59491193,\n",
      "        0.59099805, 0.58708417, 0.58317029, 0.57925642, 0.57534242, 0.57142854,\n",
      "        0.56751466, 0.56360078, 0.55968690, 0.55577302, 0.55185914, 0.54794526,\n",
      "        0.54403126, 0.54011738, 0.53620350, 0.53228962, 0.52837574, 0.52446187,\n",
      "        0.52054799, 0.51663411, 0.51272011, 0.50880623, 0.50489235, 0.50097847,\n",
      "        0.49706459, 0.49315071, 0.48923683, 0.48532295, 0.48140895, 0.47749507,\n",
      "        0.47358119, 0.46966732, 0.46575344, 0.46183956, 0.45792568, 0.45401180,\n",
      "        0.45009780, 0.44618392, 0.44227004, 0.43835616, 0.43444228, 0.43052840,\n",
      "        0.42661452, 0.42270064, 0.41878664, 0.41487277, 0.41095889, 0.40704501,\n",
      "        0.40313113, 0.39921725, 0.39530337, 0.39138949, 0.38747549, 0.38356161,\n",
      "        0.37964773, 0.37573385, 0.37181997, 0.36790609, 0.36399221, 0.36007833,\n",
      "        0.35616434, 0.35225046, 0.34833658, 0.34442270, 0.34050882, 0.33659494,\n",
      "        0.33268106, 0.32876718, 0.32485318, 0.32093930, 0.31702542, 0.31311154,\n",
      "        0.30919766, 0.30528378, 0.30136991, 0.29745603, 0.29354203, 0.28962815,\n",
      "        0.28571427, 0.28180039, 0.27788651, 0.27397263, 0.27005875, 0.26614487,\n",
      "        0.26223087, 0.25831699, 0.25440311, 0.25048923, 0.24657536, 0.24266148,\n",
      "        0.23874760, 0.23483372, 0.23091972, 0.22700584, 0.22309196, 0.21917808,\n",
      "        0.21526420, 0.21135032, 0.20743644, 0.20352256, 0.19960856, 0.19569468,\n",
      "        0.19178081, 0.18786693, 0.18395305, 0.18003917, 0.17612529, 0.17221141,\n",
      "        0.16829741, 0.16438353, 0.16046965, 0.15655577, 0.15264189, 0.14872801,\n",
      "        0.14481413, 0.14090025, 0.13698626, 0.13307238, 0.12915850, 0.12524462,\n",
      "        0.12133074, 0.11741686, 0.11350298, 0.10958910, 0.10567510, 0.10176122,\n",
      "        0.09784734, 0.09393346, 0.09001958, 0.08610570, 0.08219182, 0.07827795,\n",
      "        0.07436395, 0.07045007, 0.06653619, 0.06262231, 0.05870843, 0.05479455,\n",
      "        0.05088067, 0.04696679, 0.04305279, 0.03913891, 0.03522503, 0.03131115,\n",
      "        0.02739727, 0.02348340, 0.01956952, 0.01565564, 0.01174164, 0.00782776,\n",
      "        0.00391388, 0.        ])\n",
      "Tensor(shape=[], dtype=float32, place=Place(cpu), stop_gradient=True,\n",
      "       129418.56250000)\n",
      "129418.56270064856\n",
      "255.5\n",
      "[0.         0.00391389 0.00782779 0.01174168 0.01565558 0.01956947\n",
      " 0.02348337 0.02739726 0.03131115 0.03522505 0.03913894 0.04305284\n",
      " 0.04696673 0.05088063 0.05479452 0.05870841 0.06262231 0.0665362\n",
      " 0.0704501  0.07436399 0.07827789 0.08219178 0.08610568 0.09001957\n",
      " 0.09393346 0.09784736 0.10176125 0.10567515 0.10958904 0.11350294\n",
      " 0.11741683 0.12133072 0.12524462 0.12915851 0.13307241 0.1369863\n",
      " 0.1409002  0.14481409 0.14872798 0.15264188 0.15655577 0.16046967\n",
      " 0.16438356 0.16829746 0.17221135 0.17612524 0.18003914 0.18395303\n",
      " 0.18786693 0.19178082 0.19569472 0.19960861 0.2035225  0.2074364\n",
      " 0.21135029 0.21526419 0.21917808 0.22309198 0.22700587 0.23091977\n",
      " 0.23483366 0.23874755 0.24266145 0.24657534 0.25048924 0.25440313\n",
      " 0.25831703 0.26223092 0.26614481 0.27005871 0.2739726  0.2778865\n",
      " 0.28180039 0.28571429 0.28962818 0.29354207 0.29745597 0.30136986\n",
      " 0.30528376 0.30919765 0.31311155 0.31702544 0.32093933 0.32485323\n",
      " 0.32876712 0.33268102 0.33659491 0.34050881 0.3444227  0.34833659\n",
      " 0.35225049 0.35616438 0.36007828 0.36399217 0.36790607 0.37181996\n",
      " 0.37573386 0.37964775 0.38356164 0.38747554 0.39138943 0.39530333\n",
      " 0.39921722 0.40313112 0.40704501 0.4109589  0.4148728  0.41878669\n",
      " 0.42270059 0.42661448 0.43052838 0.43444227 0.43835616 0.44227006\n",
      " 0.44618395 0.45009785 0.45401174 0.45792564 0.46183953 0.46575342\n",
      " 0.46966732 0.47358121 0.47749511 0.481409   0.4853229  0.48923679\n",
      " 0.49315068 0.49706458 0.50097847 0.50489237 0.50880626 0.51272016\n",
      " 0.51663405 0.52054795 0.52446184 0.52837573 0.53228963 0.53620352\n",
      " 0.54011742 0.54403131 0.54794521 0.5518591  0.55577299 0.55968689\n",
      " 0.56360078 0.56751468 0.57142857 0.57534247 0.57925636 0.58317025\n",
      " 0.58708415 0.59099804 0.59491194 0.59882583 0.60273973 0.60665362\n",
      " 0.61056751 0.61448141 0.6183953  0.6223092  0.62622309 0.63013699\n",
      " 0.63405088 0.63796477 0.64187867 0.64579256 0.64970646 0.65362035\n",
      " 0.65753425 0.66144814 0.66536204 0.66927593 0.67318982 0.67710372\n",
      " 0.68101761 0.68493151 0.6888454  0.6927593  0.69667319 0.70058708\n",
      " 0.70450098 0.70841487 0.71232877 0.71624266 0.72015656 0.72407045\n",
      " 0.72798434 0.73189824 0.73581213 0.73972603 0.74363992 0.74755382\n",
      " 0.75146771 0.7553816  0.7592955  0.76320939 0.76712329 0.77103718\n",
      " 0.77495108 0.77886497 0.78277886 0.78669276 0.79060665 0.79452055\n",
      " 0.79843444 0.80234834 0.80626223 0.81017613 0.81409002 0.81800391\n",
      " 0.82191781 0.8258317  0.8297456  0.83365949 0.83757339 0.84148728\n",
      " 0.84540117 0.84931507 0.85322896 0.85714286 0.86105675 0.86497065\n",
      " 0.86888454 0.87279843 0.87671233 0.88062622 0.88454012 0.88845401\n",
      " 0.89236791 0.8962818  0.90019569 0.90410959 0.90802348 0.91193738\n",
      " 0.91585127 0.91976517 0.92367906 0.92759295 0.93150685 0.93542074\n",
      " 0.93933464 0.94324853 0.94716243 0.95107632 0.95499022 0.95890411\n",
      " 0.962818   0.9667319  0.97064579 0.97455969 0.97847358 0.98238748\n",
      " 0.98630137 0.99021526 0.99412916 0.99804305 0.99804305 0.99412916\n",
      " 0.99021526 0.98630137 0.98238748 0.97847358 0.97455969 0.97064579\n",
      " 0.9667319  0.962818   0.95890411 0.95499022 0.95107632 0.94716243\n",
      " 0.94324853 0.93933464 0.93542074 0.93150685 0.92759295 0.92367906\n",
      " 0.91976517 0.91585127 0.91193738 0.90802348 0.90410959 0.90019569\n",
      " 0.8962818  0.89236791 0.88845401 0.88454012 0.88062622 0.87671233\n",
      " 0.87279843 0.86888454 0.86497065 0.86105675 0.85714286 0.85322896\n",
      " 0.84931507 0.84540117 0.84148728 0.83757339 0.83365949 0.8297456\n",
      " 0.8258317  0.82191781 0.81800391 0.81409002 0.81017613 0.80626223\n",
      " 0.80234834 0.79843444 0.79452055 0.79060665 0.78669276 0.78277886\n",
      " 0.77886497 0.77495108 0.77103718 0.76712329 0.76320939 0.7592955\n",
      " 0.7553816  0.75146771 0.74755382 0.74363992 0.73972603 0.73581213\n",
      " 0.73189824 0.72798434 0.72407045 0.72015656 0.71624266 0.71232877\n",
      " 0.70841487 0.70450098 0.70058708 0.69667319 0.6927593  0.6888454\n",
      " 0.68493151 0.68101761 0.67710372 0.67318982 0.66927593 0.66536204\n",
      " 0.66144814 0.65753425 0.65362035 0.64970646 0.64579256 0.64187867\n",
      " 0.63796477 0.63405088 0.63013699 0.62622309 0.6223092  0.6183953\n",
      " 0.61448141 0.61056751 0.60665362 0.60273973 0.59882583 0.59491194\n",
      " 0.59099804 0.58708415 0.58317025 0.57925636 0.57534247 0.57142857\n",
      " 0.56751468 0.56360078 0.55968689 0.55577299 0.5518591  0.54794521\n",
      " 0.54403131 0.54011742 0.53620352 0.53228963 0.52837573 0.52446184\n",
      " 0.52054795 0.51663405 0.51272016 0.50880626 0.50489237 0.50097847\n",
      " 0.49706458 0.49315068 0.48923679 0.4853229  0.481409   0.47749511\n",
      " 0.47358121 0.46966732 0.46575342 0.46183953 0.45792564 0.45401174\n",
      " 0.45009785 0.44618395 0.44227006 0.43835616 0.43444227 0.43052838\n",
      " 0.42661448 0.42270059 0.41878669 0.4148728  0.4109589  0.40704501\n",
      " 0.40313112 0.39921722 0.39530333 0.39138943 0.38747554 0.38356164\n",
      " 0.37964775 0.37573386 0.37181996 0.36790607 0.36399217 0.36007828\n",
      " 0.35616438 0.35225049 0.34833659 0.3444227  0.34050881 0.33659491\n",
      " 0.33268102 0.32876712 0.32485323 0.32093933 0.31702544 0.31311155\n",
      " 0.30919765 0.30528376 0.30136986 0.29745597 0.29354207 0.28962818\n",
      " 0.28571429 0.28180039 0.2778865  0.2739726  0.27005871 0.26614481\n",
      " 0.26223092 0.25831703 0.25440313 0.25048924 0.24657534 0.24266145\n",
      " 0.23874755 0.23483366 0.23091977 0.22700587 0.22309198 0.21917808\n",
      " 0.21526419 0.21135029 0.2074364  0.2035225  0.19960861 0.19569472\n",
      " 0.19178082 0.18786693 0.18395303 0.18003914 0.17612524 0.17221135\n",
      " 0.16829746 0.16438356 0.16046967 0.15655577 0.15264188 0.14872798\n",
      " 0.14481409 0.1409002  0.1369863  0.13307241 0.12915851 0.12524462\n",
      " 0.12133072 0.11741683 0.11350294 0.10958904 0.10567515 0.10176125\n",
      " 0.09784736 0.09393346 0.09001957 0.08610568 0.08219178 0.07827789\n",
      " 0.07436399 0.0704501  0.0665362  0.06262231 0.05870841 0.05479452\n",
      " 0.05088063 0.04696673 0.04305284 0.03913894 0.03522505 0.03131115\n",
      " 0.02739726 0.02348337 0.01956947 0.01565558 0.01174168 0.00782779\n",
      " 0.00391389 0.        ]\n"
     ]
    }
   ],
   "source": [
    "import paddle\n",
    "from paddle import Tensor\n",
    "import math\n",
    "import numpy as np\n",
    "\n",
    "# 设置环境为CPU\n",
    "paddle.set_device('cpu')\n",
    "def _len_guards(M: int) -> bool:\n",
    "    \"\"\"Handle small or incorrect window lengths.\"\"\"\n",
    "    if int(M) != M or M < 0:\n",
    "        raise ValueError('Window length M must be a non-negative integer')\n",
    "    return M <= 1\n",
    "\n",
    "def _extend(M: int, sym: bool) -> bool:\n",
    "    \"\"\"Extend window by 1 sample if needed for DFT-even symmetry.\"\"\"\n",
    "    if not sym:\n",
    "        return M + 1, True\n",
    "    else:\n",
    "        return M, False\n",
    "\n",
    "def _truncate(w: Tensor, needed: bool) -> Tensor:\n",
    "    \"\"\"Truncate window by 1 sample if needed for DFT-even symmetry.\"\"\"\n",
    "    if needed:\n",
    "        return w[:-1]\n",
    "    else:\n",
    "        return w\n",
    "\n",
    "def _general_cosine(\n",
    "    M: int, a: float, sym: bool = True, dtype: str = 'float32'\n",
    ") -> Tensor:\n",
    "    \"\"\"Compute a generic weighted sum of cosine terms window.\n",
    "    This function is consistent with scipy.signal.windows.general_cosine().\n",
    "    \"\"\"\n",
    "    if _len_guards(M):\n",
    "        return paddle.ones((M,), dtype=dtype)\n",
    "    M, needs_trunc = _extend(M, sym)\n",
    "    fac = paddle.linspace(-math.pi, math.pi, M, dtype=dtype)\n",
    "    w = paddle.zeros((M,), dtype=dtype)\n",
    "    for k in range(len(a)):\n",
    "        w += a[k] * paddle.cos(k * fac)\n",
    "    return _truncate(w, needs_trunc)\n",
    "\n",
    "def _bartlett(M: int, sym: bool = True, dtype: str = 'float32') -> Tensor:\n",
    "    \"\"\"\n",
    "    Computes the Bartlett window.\n",
    "    This function is consistent with scipy.signal.windows.bartlett().\n",
    "    \"\"\"\n",
    "    if _len_guards(M):\n",
    "        A = paddle.ones((M,), dtype=dtype)\n",
    "        # print(A)\n",
    "        return A\n",
    "    M, needs_trunc = _extend(M, sym)\n",
    "    # print(M)\n",
    "\n",
    "    n = paddle.arange(0, M, dtype=dtype)\n",
    "    M = paddle.to_tensor(M, dtype=dtype)\n",
    "    print(2.0*n/(M-1))\n",
    "    # print(n)\n",
    "    w = paddle.where(\n",
    "        paddle.less_equal(n, (M - 1) / 2.0),\n",
    "        2.0 * n / (M - 1),\n",
    "        2.0 - 2.0 * n / (M - 1),\n",
    "    )\n",
    "    print(w)\n",
    "\n",
    "    return _truncate(w, needs_trunc)\n",
    "\n",
    "window_paddle_bartlett=_bartlett(512)\n",
    "print(paddle.i0(paddle.to_tensor(14.0, dtype='float32')))\n",
    "print(np.i0(14.0))\n",
    "def _kaiser(\n",
    "    M: int, beta: float, sym: bool = True, dtype: str = 'float32'\n",
    ") -> Tensor:\n",
    "    \"\"\"Compute the Kaiser window.\n",
    "    This function is consistent with scipy.signal.windows.kaiser().\n",
    "    \"\"\"\n",
    "    if _len_guards(M):\n",
    "        return paddle.ones((M,), dtype=dtype)\n",
    "    M, needs_trunc = _extend(M, sym)\n",
    "\n",
    "    beta = paddle.to_tensor(beta, dtype=dtype)\n",
    "\n",
    "    n = paddle.arange(0, M, dtype=dtype)\n",
    "    M = paddle.to_tensor(M, dtype=dtype)\n",
    "    alpha = paddle.to_tensor((M - 1) / 2.0, dtype=dtype)\n",
    "    w = paddle.i0(\n",
    "        beta * paddle.sqrt(1 - ((n - alpha) / alpha) ** 2.0)\n",
    "    ) / paddle.i0(beta)\n",
    "\n",
    "    return _truncate(w, needs_trunc)\n",
    "\n",
    "def _nuttall(M: int, sym: bool = True, dtype: str = 'float32') -> Tensor:\n",
    "    \"\"\"Nuttall window.\n",
    "    This function is consistent with scipy.signal.windows.nuttall().\n",
    "    \"\"\"\n",
    "    a=paddle.to_tensor([0.3635819, 0.4891775, 0.1365995, 0.0106411], dtype=dtype)\n",
    "    return _general_cosine(\n",
    "        M, a=a, sym=sym, dtype=dtype\n",
    "    )\n",
    "\n",
    "\n",
    "def bartlett(M, sym=True):\n",
    "    \n",
    "    # Docstring adapted from NumPy's bartlett function\n",
    "    if _len_guards(M):\n",
    "        a= np.ones(M)\n",
    "        # print(a)\n",
    "        return a\n",
    "    M, needs_trunc = _extend(M, sym)\n",
    "    # print(M)\n",
    "\n",
    "    n = np.arange(0, M)\n",
    "    # print(n)\n",
    "    o =  (M - 1) / 2.0\n",
    "    print(o)\n",
    "    w = np.where(np.less_equal(n, o),\n",
    "                 2.0 * n / (M - 1), 2.0 - 2.0 * n / (M - 1))\n",
    "    print(w)\n",
    "\n",
    "    return _truncate(w, needs_trunc)\n",
    "\n",
    "window_scipy_bartlett = bartlett(512)\n",
    "# print(window)\n",
    "\n",
    "np.testing.assert_array_almost_equal(\n",
    "            window_scipy_bartlett, window_paddle_bartlett.numpy(), decimal=5\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(shape=[512], dtype=float32, place=Place(cpu), stop_gradient=True,\n",
      "       [0.        , 0.00391389, 0.00782779, 0.01174168, 0.01565558, 0.01956947,\n",
      "        0.02348337, 0.02739726, 0.03131115, 0.03522505, 0.03913894, 0.04305284,\n",
      "        0.04696673, 0.05088063, 0.05479452, 0.05870841, 0.06262231, 0.06653620,\n",
      "        0.07045010, 0.07436399, 0.07827789, 0.08219178, 0.08610567, 0.09001957,\n",
      "        0.09393346, 0.09784736, 0.10176125, 0.10567515, 0.10958904, 0.11350293,\n",
      "        0.11741683, 0.12133072, 0.12524462, 0.12915851, 0.13307241, 0.13698630,\n",
      "        0.14090019, 0.14481409, 0.14872798, 0.15264188, 0.15655577, 0.16046967,\n",
      "        0.16438356, 0.16829745, 0.17221135, 0.17612524, 0.18003914, 0.18395303,\n",
      "        0.18786693, 0.19178082, 0.19569471, 0.19960861, 0.20352250, 0.20743640,\n",
      "        0.21135029, 0.21526419, 0.21917808, 0.22309197, 0.22700587, 0.23091976,\n",
      "        0.23483366, 0.23874755, 0.24266145, 0.24657534, 0.25048923, 0.25440314,\n",
      "        0.25831702, 0.26223093, 0.26614481, 0.27005872, 0.27397260, 0.27788651,\n",
      "        0.28180039, 0.28571430, 0.28962818, 0.29354209, 0.29745597, 0.30136988,\n",
      "        0.30528376, 0.30919766, 0.31311154, 0.31702545, 0.32093933, 0.32485324,\n",
      "        0.32876712, 0.33268103, 0.33659491, 0.34050882, 0.34442270, 0.34833661,\n",
      "        0.35225049, 0.35616440, 0.36007828, 0.36399218, 0.36790606, 0.37181997,\n",
      "        0.37573385, 0.37964776, 0.38356164, 0.38747555, 0.39138943, 0.39530334,\n",
      "        0.39921722, 0.40313113, 0.40704501, 0.41095892, 0.41487280, 0.41878670,\n",
      "        0.42270058, 0.42661449, 0.43052837, 0.43444228, 0.43835616, 0.44227007,\n",
      "        0.44618395, 0.45009786, 0.45401174, 0.45792565, 0.46183953, 0.46575344,\n",
      "        0.46966732, 0.47358122, 0.47749510, 0.48140901, 0.48532289, 0.48923680,\n",
      "        0.49315068, 0.49706459, 0.50097847, 0.50489235, 0.50880629, 0.51272017,\n",
      "        0.51663405, 0.52054793, 0.52446187, 0.52837574, 0.53228962, 0.53620350,\n",
      "        0.54011744, 0.54403132, 0.54794520, 0.55185908, 0.55577302, 0.55968690,\n",
      "        0.56360078, 0.56751466, 0.57142860, 0.57534248, 0.57925636, 0.58317024,\n",
      "        0.58708417, 0.59099805, 0.59491193, 0.59882581, 0.60273975, 0.60665363,\n",
      "        0.61056751, 0.61448139, 0.61839533, 0.62230921, 0.62622309, 0.63013697,\n",
      "        0.63405091, 0.63796479, 0.64187866, 0.64579254, 0.64970648, 0.65362036,\n",
      "        0.65753424, 0.66144812, 0.66536206, 0.66927594, 0.67318982, 0.67710370,\n",
      "        0.68101764, 0.68493152, 0.68884540, 0.69275928, 0.69667321, 0.70058709,\n",
      "        0.70450097, 0.70841485, 0.71232879, 0.71624267, 0.72015655, 0.72407043,\n",
      "        0.72798437, 0.73189825, 0.73581213, 0.73972601, 0.74363995, 0.74755383,\n",
      "        0.75146770, 0.75538158, 0.75929552, 0.76320940, 0.76712328, 0.77103716,\n",
      "        0.77495110, 0.77886498, 0.78277886, 0.78669274, 0.79060668, 0.79452056,\n",
      "        0.79843444, 0.80234832, 0.80626225, 0.81017613, 0.81409001, 0.81800389,\n",
      "        0.82191783, 0.82583171, 0.82974559, 0.83365947, 0.83757341, 0.84148729,\n",
      "        0.84540117, 0.84931505, 0.85322899, 0.85714287, 0.86105675, 0.86497062,\n",
      "        0.86888456, 0.87279844, 0.87671232, 0.88062620, 0.88454014, 0.88845402,\n",
      "        0.89236790, 0.89628178, 0.90019572, 0.90410960, 0.90802348, 0.91193736,\n",
      "        0.91585129, 0.91976517, 0.92367905, 0.92759293, 0.93150687, 0.93542075,\n",
      "        0.93933463, 0.94324851, 0.94716245, 0.95107633, 0.95499021, 0.95890409,\n",
      "        0.96281803, 0.96673191, 0.97064579, 0.97455966, 0.97847360, 0.98238748,\n",
      "        0.98630136, 0.99021524, 0.99412918, 0.99804306, 1.00195694, 1.00587082,\n",
      "        1.00978470, 1.01369858, 1.01761258, 1.02152646, 1.02544034, 1.02935421,\n",
      "        1.03326809, 1.03718197, 1.04109585, 1.04500973, 1.04892373, 1.05283761,\n",
      "        1.05675149, 1.06066537, 1.06457925, 1.06849313, 1.07240701, 1.07632089,\n",
      "        1.08023489, 1.08414876, 1.08806264, 1.09197652, 1.09589040, 1.09980428,\n",
      "        1.10371816, 1.10763204, 1.11154604, 1.11545992, 1.11937380, 1.12328768,\n",
      "        1.12720156, 1.13111544, 1.13502932, 1.13894320, 1.14285719, 1.14677107,\n",
      "        1.15068495, 1.15459883, 1.15851271, 1.16242659, 1.16634047, 1.17025435,\n",
      "        1.17416835, 1.17808223, 1.18199611, 1.18590999, 1.18982387, 1.19373775,\n",
      "        1.19765162, 1.20156550, 1.20547950, 1.20939338, 1.21330726, 1.21722114,\n",
      "        1.22113502, 1.22504890, 1.22896278, 1.23287666, 1.23679066, 1.24070454,\n",
      "        1.24461842, 1.24853230, 1.25244617, 1.25636005, 1.26027393, 1.26418781,\n",
      "        1.26810181, 1.27201569, 1.27592957, 1.27984345, 1.28375733, 1.28767121,\n",
      "        1.29158509, 1.29549897, 1.29941297, 1.30332685, 1.30724072, 1.31115460,\n",
      "        1.31506848, 1.31898236, 1.32289624, 1.32681012, 1.33072412, 1.33463800,\n",
      "        1.33855188, 1.34246576, 1.34637964, 1.35029352, 1.35420740, 1.35812128,\n",
      "        1.36203527, 1.36594915, 1.36986303, 1.37377691, 1.37769079, 1.38160467,\n",
      "        1.38551855, 1.38943243, 1.39334643, 1.39726031, 1.40117419, 1.40508807,\n",
      "        1.40900195, 1.41291583, 1.41682971, 1.42074358, 1.42465758, 1.42857146,\n",
      "        1.43248534, 1.43639922, 1.44031310, 1.44422698, 1.44814086, 1.45205474,\n",
      "        1.45596874, 1.45988262, 1.46379650, 1.46771038, 1.47162426, 1.47553813,\n",
      "        1.47945201, 1.48336589, 1.48727989, 1.49119377, 1.49510765, 1.49902153,\n",
      "        1.50293541, 1.50684929, 1.51076317, 1.51467705, 1.51859105, 1.52250493,\n",
      "        1.52641881, 1.53033268, 1.53424656, 1.53816044, 1.54207432, 1.54598820,\n",
      "        1.54990220, 1.55381608, 1.55772996, 1.56164384, 1.56555772, 1.56947160,\n",
      "        1.57338548, 1.57729936, 1.58121336, 1.58512723, 1.58904111, 1.59295499,\n",
      "        1.59686887, 1.60078275, 1.60469663, 1.60861051, 1.61252451, 1.61643839,\n",
      "        1.62035227, 1.62426615, 1.62818003, 1.63209391, 1.63600779, 1.63992167,\n",
      "        1.64383566, 1.64774954, 1.65166342, 1.65557730, 1.65949118, 1.66340506,\n",
      "        1.66731894, 1.67123282, 1.67514682, 1.67906070, 1.68297458, 1.68688846,\n",
      "        1.69080234, 1.69471622, 1.69863009, 1.70254397, 1.70645797, 1.71037185,\n",
      "        1.71428573, 1.71819961, 1.72211349, 1.72602737, 1.72994125, 1.73385513,\n",
      "        1.73776913, 1.74168301, 1.74559689, 1.74951077, 1.75342464, 1.75733852,\n",
      "        1.76125240, 1.76516628, 1.76908028, 1.77299416, 1.77690804, 1.78082192,\n",
      "        1.78473580, 1.78864968, 1.79256356, 1.79647744, 1.80039144, 1.80430532,\n",
      "        1.80821919, 1.81213307, 1.81604695, 1.81996083, 1.82387471, 1.82778859,\n",
      "        1.83170259, 1.83561647, 1.83953035, 1.84344423, 1.84735811, 1.85127199,\n",
      "        1.85518587, 1.85909975, 1.86301374, 1.86692762, 1.87084150, 1.87475538,\n",
      "        1.87866926, 1.88258314, 1.88649702, 1.89041090, 1.89432490, 1.89823878,\n",
      "        1.90215266, 1.90606654, 1.90998042, 1.91389430, 1.91780818, 1.92172205,\n",
      "        1.92563605, 1.92954993, 1.93346381, 1.93737769, 1.94129157, 1.94520545,\n",
      "        1.94911933, 1.95303321, 1.95694721, 1.96086109, 1.96477497, 1.96868885,\n",
      "        1.97260273, 1.97651660, 1.98043048, 1.98434436, 1.98825836, 1.99217224,\n",
      "        1.99608612, 2.        ])\n",
      "Tensor(shape=[512], dtype=float32, place=Place(cpu), stop_gradient=True,\n",
      "       [0.        , 0.00391389, 0.00782779, 0.01174168, 0.01565558, 0.01956947,\n",
      "        0.02348337, 0.02739726, 0.03131115, 0.03522505, 0.03913894, 0.04305284,\n",
      "        0.04696673, 0.05088063, 0.05479452, 0.05870841, 0.06262231, 0.06653620,\n",
      "        0.07045010, 0.07436399, 0.07827789, 0.08219178, 0.08610567, 0.09001957,\n",
      "        0.09393346, 0.09784736, 0.10176125, 0.10567515, 0.10958904, 0.11350293,\n",
      "        0.11741683, 0.12133072, 0.12524462, 0.12915851, 0.13307241, 0.13698630,\n",
      "        0.14090019, 0.14481409, 0.14872798, 0.15264188, 0.15655577, 0.16046967,\n",
      "        0.16438356, 0.16829745, 0.17221135, 0.17612524, 0.18003914, 0.18395303,\n",
      "        0.18786693, 0.19178082, 0.19569471, 0.19960861, 0.20352250, 0.20743640,\n",
      "        0.21135029, 0.21526419, 0.21917808, 0.22309197, 0.22700587, 0.23091976,\n",
      "        0.23483366, 0.23874755, 0.24266145, 0.24657534, 0.25048923, 0.25440314,\n",
      "        0.25831702, 0.26223093, 0.26614481, 0.27005872, 0.27397260, 0.27788651,\n",
      "        0.28180039, 0.28571430, 0.28962818, 0.29354209, 0.29745597, 0.30136988,\n",
      "        0.30528376, 0.30919766, 0.31311154, 0.31702545, 0.32093933, 0.32485324,\n",
      "        0.32876712, 0.33268103, 0.33659491, 0.34050882, 0.34442270, 0.34833661,\n",
      "        0.35225049, 0.35616440, 0.36007828, 0.36399218, 0.36790606, 0.37181997,\n",
      "        0.37573385, 0.37964776, 0.38356164, 0.38747555, 0.39138943, 0.39530334,\n",
      "        0.39921722, 0.40313113, 0.40704501, 0.41095892, 0.41487280, 0.41878670,\n",
      "        0.42270058, 0.42661449, 0.43052837, 0.43444228, 0.43835616, 0.44227007,\n",
      "        0.44618395, 0.45009786, 0.45401174, 0.45792565, 0.46183953, 0.46575344,\n",
      "        0.46966732, 0.47358122, 0.47749510, 0.48140901, 0.48532289, 0.48923680,\n",
      "        0.49315068, 0.49706459, 0.50097847, 0.50489235, 0.50880629, 0.51272017,\n",
      "        0.51663405, 0.52054793, 0.52446187, 0.52837574, 0.53228962, 0.53620350,\n",
      "        0.54011744, 0.54403132, 0.54794520, 0.55185908, 0.55577302, 0.55968690,\n",
      "        0.56360078, 0.56751466, 0.57142860, 0.57534248, 0.57925636, 0.58317024,\n",
      "        0.58708417, 0.59099805, 0.59491193, 0.59882581, 0.60273975, 0.60665363,\n",
      "        0.61056751, 0.61448139, 0.61839533, 0.62230921, 0.62622309, 0.63013697,\n",
      "        0.63405091, 0.63796479, 0.64187866, 0.64579254, 0.64970648, 0.65362036,\n",
      "        0.65753424, 0.66144812, 0.66536206, 0.66927594, 0.67318982, 0.67710370,\n",
      "        0.68101764, 0.68493152, 0.68884540, 0.69275928, 0.69667321, 0.70058709,\n",
      "        0.70450097, 0.70841485, 0.71232879, 0.71624267, 0.72015655, 0.72407043,\n",
      "        0.72798437, 0.73189825, 0.73581213, 0.73972601, 0.74363995, 0.74755383,\n",
      "        0.75146770, 0.75538158, 0.75929552, 0.76320940, 0.76712328, 0.77103716,\n",
      "        0.77495110, 0.77886498, 0.78277886, 0.78669274, 0.79060668, 0.79452056,\n",
      "        0.79843444, 0.80234832, 0.80626225, 0.81017613, 0.81409001, 0.81800389,\n",
      "        0.82191783, 0.82583171, 0.82974559, 0.83365947, 0.83757341, 0.84148729,\n",
      "        0.84540117, 0.84931505, 0.85322899, 0.85714287, 0.86105675, 0.86497062,\n",
      "        0.86888456, 0.87279844, 0.87671232, 0.88062620, 0.88454014, 0.88845402,\n",
      "        0.89236790, 0.89628178, 0.90019572, 0.90410960, 0.90802348, 0.91193736,\n",
      "        0.91585129, 0.91976517, 0.92367905, 0.92759293, 0.93150687, 0.93542075,\n",
      "        0.93933463, 0.94324851, 0.94716245, 0.95107633, 0.95499021, 0.95890409,\n",
      "        0.96281803, 0.96673191, 0.97064579, 0.97455966, 0.97847360, 0.98238748,\n",
      "        0.98630136, 0.99021524, 0.99412918, 0.99804306, 0.99804306, 0.99412918,\n",
      "        0.99021530, 0.98630142, 0.98238742, 0.97847354, 0.97455966, 0.97064579,\n",
      "        0.96673191, 0.96281803, 0.95890415, 0.95499027, 0.95107627, 0.94716239,\n",
      "        0.94324851, 0.93933463, 0.93542075, 0.93150687, 0.92759299, 0.92367911,\n",
      "        0.91976511, 0.91585124, 0.91193736, 0.90802348, 0.90410960, 0.90019572,\n",
      "        0.89628184, 0.89236796, 0.88845396, 0.88454008, 0.88062620, 0.87671232,\n",
      "        0.87279844, 0.86888456, 0.86497068, 0.86105680, 0.85714281, 0.85322893,\n",
      "        0.84931505, 0.84540117, 0.84148729, 0.83757341, 0.83365953, 0.82974565,\n",
      "        0.82583165, 0.82191777, 0.81800389, 0.81409001, 0.81017613, 0.80626225,\n",
      "        0.80234838, 0.79843450, 0.79452050, 0.79060662, 0.78669274, 0.78277886,\n",
      "        0.77886498, 0.77495110, 0.77103722, 0.76712334, 0.76320934, 0.75929546,\n",
      "        0.75538158, 0.75146770, 0.74755383, 0.74363995, 0.73972607, 0.73581219,\n",
      "        0.73189819, 0.72798431, 0.72407043, 0.72015655, 0.71624267, 0.71232879,\n",
      "        0.70841491, 0.70450103, 0.70058703, 0.69667315, 0.69275928, 0.68884540,\n",
      "        0.68493152, 0.68101764, 0.67710376, 0.67318988, 0.66927588, 0.66536200,\n",
      "        0.66144812, 0.65753424, 0.65362036, 0.64970648, 0.64579260, 0.64187872,\n",
      "        0.63796473, 0.63405085, 0.63013697, 0.62622309, 0.62230921, 0.61839533,\n",
      "        0.61448145, 0.61056757, 0.60665357, 0.60273969, 0.59882581, 0.59491193,\n",
      "        0.59099805, 0.58708417, 0.58317029, 0.57925642, 0.57534242, 0.57142854,\n",
      "        0.56751466, 0.56360078, 0.55968690, 0.55577302, 0.55185914, 0.54794526,\n",
      "        0.54403126, 0.54011738, 0.53620350, 0.53228962, 0.52837574, 0.52446187,\n",
      "        0.52054799, 0.51663411, 0.51272011, 0.50880623, 0.50489235, 0.50097847,\n",
      "        0.49706459, 0.49315071, 0.48923683, 0.48532295, 0.48140895, 0.47749507,\n",
      "        0.47358119, 0.46966732, 0.46575344, 0.46183956, 0.45792568, 0.45401180,\n",
      "        0.45009780, 0.44618392, 0.44227004, 0.43835616, 0.43444228, 0.43052840,\n",
      "        0.42661452, 0.42270064, 0.41878664, 0.41487277, 0.41095889, 0.40704501,\n",
      "        0.40313113, 0.39921725, 0.39530337, 0.39138949, 0.38747549, 0.38356161,\n",
      "        0.37964773, 0.37573385, 0.37181997, 0.36790609, 0.36399221, 0.36007833,\n",
      "        0.35616434, 0.35225046, 0.34833658, 0.34442270, 0.34050882, 0.33659494,\n",
      "        0.33268106, 0.32876718, 0.32485318, 0.32093930, 0.31702542, 0.31311154,\n",
      "        0.30919766, 0.30528378, 0.30136991, 0.29745603, 0.29354203, 0.28962815,\n",
      "        0.28571427, 0.28180039, 0.27788651, 0.27397263, 0.27005875, 0.26614487,\n",
      "        0.26223087, 0.25831699, 0.25440311, 0.25048923, 0.24657536, 0.24266148,\n",
      "        0.23874760, 0.23483372, 0.23091972, 0.22700584, 0.22309196, 0.21917808,\n",
      "        0.21526420, 0.21135032, 0.20743644, 0.20352256, 0.19960856, 0.19569468,\n",
      "        0.19178081, 0.18786693, 0.18395305, 0.18003917, 0.17612529, 0.17221141,\n",
      "        0.16829741, 0.16438353, 0.16046965, 0.15655577, 0.15264189, 0.14872801,\n",
      "        0.14481413, 0.14090025, 0.13698626, 0.13307238, 0.12915850, 0.12524462,\n",
      "        0.12133074, 0.11741686, 0.11350298, 0.10958910, 0.10567510, 0.10176122,\n",
      "        0.09784734, 0.09393346, 0.09001958, 0.08610570, 0.08219182, 0.07827795,\n",
      "        0.07436395, 0.07045007, 0.06653619, 0.06262231, 0.05870843, 0.05479455,\n",
      "        0.05088067, 0.04696679, 0.04305279, 0.03913891, 0.03522503, 0.03131115,\n",
      "        0.02739727, 0.02348340, 0.01956952, 0.01565564, 0.01174164, 0.00782776,\n",
      "        0.00391388, 0.        ])\n",
      "(512,)\n",
      "(512,)\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "import unittest\n",
    "\n",
    "import numpy as np\n",
    "from scipy import signal\n",
    "import math\n",
    "import paddle\n",
    "import paddle.audio\n",
    "\n",
    "\n",
    "class TestAudioFuncitons():\n",
    "    def test_bartlett_nuttall_kaiser_window(self, n_fft: int=512):\n",
    "        paddle.disable_static()\n",
    "\n",
    "        window_scipy_bartlett = signal.windows.bartlett(n_fft)\n",
    "        window_paddle_bartlett = _bartlett(n_fft)\n",
    "        np.testing.assert_array_almost_equal(\n",
    "            window_scipy_bartlett, window_paddle_bartlett.numpy(), decimal=5\n",
    "        )\n",
    "\n",
    "        window_scipy_nuttall = signal.windows.nuttall(n_fft)\n",
    "        window_paddle_nuttall = _nuttall(n_fft)\n",
    "        np.testing.assert_array_almost_equal(\n",
    "            window_scipy_nuttall, window_paddle_nuttall.numpy(), decimal=5\n",
    "        )\n",
    "\n",
    "        window_scipy_kaiser = signal.windows.kaiser(n_fft, beta=14.0)\n",
    "        print(window_scipy_kaiser.shape)\n",
    "        window_paddle_kaiser = _kaiser(n_fft, 14.0)\n",
    "        print(window_paddle_kaiser.numpy().shape)\n",
    "        np.testing.assert_array_almost_equal(\n",
    "            window_scipy_kaiser, window_paddle_kaiser.numpy(), decimal=5\n",
    "        )\n",
    "\n",
    "\n",
    "a = TestAudioFuncitons()\n",
    "a.test_bartlett_nuttall_kaiser_window()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建一个随机张量\n",
    "x = torch.randn(2, 3, 4)\n",
    "\n",
    "# 创建较小的裁剪边界张量，利用广播机制\n",
    "min_tensor = torch.tensor([-1.0, -0.5, -0.5, 2])  # 形状为 (2,)\n",
    "max_tensor = torch.tensor([0.5, 1.0, 0.5, 4])    # 形状为 (2,)\n",
    "\n",
    "# PyTorch 将自动扩展 min_tensor 和 max_tensor 以匹配 x 的形状\n",
    "x_clipped = torch.clip(x, min=min_tensor, max=max_tensor)\n",
    "print(\"Clipped Tensor with Broadcasting Boundaries:\")\n",
    "print(x_clipped)\n",
    "\n",
    "# 注意：这里的广播是沿着最后一个维度进行的（对于二维张量来说，就是列方向）\n",
    "# 因此，min_tensor 和 max_tensor 的每个元素会分别应用到 x 的每一列上"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 只设置最小值\n",
    "x_clipped_min = torch.clip(x, min=0.0)\n",
    "\n",
    "# 只设置最大值\n",
    "x_clipped_max = torch.clip(x, max=1.0)\n",
    "\n",
    "print(\"Clipped Tensor with Only Min Boundary:\")\n",
    "print(x_clipped_min)\n",
    "print(\"Clipped Tensor with Only Max Boundary:\")\n",
    "print(x_clipped_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "crow_indices = [0, 2, 4, 0, 2, 3]\n",
    "col_indices = [0, 1, 0, 1, 2, 4, 3, 0]\n",
    "values = [1, 2, 3, 4, 5, 6, 7, 8]\n",
    "sparse_tensor = torch.sparse_csr_tensor(torch.tensor(crow_indices, dtype=torch.int64),\n",
    "                        torch.tensor(col_indices, dtype=torch.int64),\n",
    "                        torch.tensor(values), dtype=torch.double)\n",
    "\n",
    "print(sparse_tensor)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import paddle\n",
    "\n",
    "dense_3d_tensor = paddle.to_tensor([[[1, 0, 0], [0, 2, 0], [3, 0, 0]],\n",
    "                                    [[0, 0, 4], [5, 0, 0], [0, 6, 0]]])\n",
    "\n",
    "print(dense_3d_tensor.to_sparse_csr())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "paddleAnd310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
