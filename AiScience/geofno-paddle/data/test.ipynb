{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "libcudnn.so.9: cannot open shared object file: No such file or directory",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 11\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mre\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# import matplotlib.pyplot as plt\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# from scipy.io import loadmat\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# import math\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# import h5py\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# import os.path\u001b[39;00m\n\u001b[0;32m---> 11\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfunctional\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mF\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtimeit\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m default_timer\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcatheter\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n",
      "File \u001b[0;32m~/miniconda3/envs/pytorchAnd310/lib/python3.10/site-packages/torch/__init__.py:290\u001b[0m\n\u001b[1;32m    288\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m USE_GLOBAL_DEPS:\n\u001b[1;32m    289\u001b[0m         _load_global_deps()\n\u001b[0;32m--> 290\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_C\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m  \u001b[38;5;66;03m# noqa: F403\u001b[39;00m\n\u001b[1;32m    292\u001b[0m \u001b[38;5;66;03m# Appease the type checker; ordinarily this binding is inserted by the\u001b[39;00m\n\u001b[1;32m    293\u001b[0m \u001b[38;5;66;03m# torch._C module initialization code in C\u001b[39;00m\n\u001b[1;32m    294\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m TYPE_CHECKING:\n",
      "\u001b[0;31mImportError\u001b[0m: libcudnn.so.9: cannot open shared object file: No such file or directory"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import glob\n",
    "import re\n",
    "# import matplotlib.pyplot as plt\n",
    "# from scipy.io import loadmat\n",
    "# import math\n",
    "# import h5py\n",
    "# import os.path\n",
    "\n",
    "\n",
    "import torch.nn.functional as F\n",
    "from timeit import default_timer\n",
    "from catheter import *\n",
    "from utilities3 import *\n",
    "from Adam import Adam\n",
    "\n",
    "torch.manual_seed(0)\n",
    "np.random.seed(0)\n",
    "torch.cuda.manual_seed(0)\n",
    "torch.backends.cudnn.deterministic = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = \"./training/\"\n",
    "INPUT_X = PATH+\"x_1d_structured_mesh.npy\"\n",
    "INPUT_Y = PATH+\"y_1d_structured_mesh.npy\"\n",
    "INPUT_para = PATH+\"data_info.npy\"\n",
    "OUTPUT = PATH+\"density_1d_data.npy\"\n",
    "n_data = 3000\n",
    "inputX_raw = np.load(INPUT_X)[:,0:n_data]\n",
    "inputY_raw = np.load(INPUT_Y)[:,0:n_data]\n",
    "inputPara_raw = np.load(INPUT_para)[:,0:n_data]\n",
    "output_raw = np.load(OUTPUT)[:,0:n_data]\n",
    "\n",
    "\n",
    "\n",
    "PATH = \"./test/\"\n",
    "INPUT_X = PATH+\"x_1d_structured_mesh.npy\"\n",
    "INPUT_Y = PATH+\"y_1d_structured_mesh.npy\"\n",
    "INPUT_para = PATH+\"data_info.npy\"\n",
    "OUTPUT = PATH+\"density_1d_data.npy\"\n",
    "n_data = 300\n",
    "inputX_test_raw = np.load(INPUT_X)[:,0:n_data]\n",
    "inputY_test_raw = np.load(INPUT_Y)[:,0:n_data]\n",
    "inputPara_test_raw = np.load(INPUT_para)[:,0:n_data]\n",
    "output_test_raw = np.load(OUTPUT)[:,0:n_data]\n",
    "\n",
    "N_s, L_x = 2001, 500\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# zero tests \n",
    "\n",
    "ntrain = 20\n",
    "ntest = 100\n",
    "\n",
    "batch_size = 20\n",
    "learning_rate = 0.001\n",
    "epochs = 1#1001\n",
    "step_size = 100\n",
    "gamma = 0.5\n",
    "\n",
    "\n",
    "modes = 64\n",
    "width = 64\n",
    "s = N_s\n",
    "\n",
    "inputX = inputX_raw[:, 0::3]\n",
    "inputY = inputY_raw[:, 0::3]\n",
    "inputPara = inputPara_raw[:, 0::3]\n",
    "output = (output_raw[:, 0::3] + output_raw[:, 1::3] + output_raw[:, 2::3])/ 3.0\n",
    "inputX = torch.tensor(inputX, dtype=torch.float).permute(1,0)\n",
    "inputY = torch.tensor(inputY, dtype=torch.float).permute(1,0)\n",
    "input = torch.stack([inputX, inputY], dim=-1)\n",
    "output = torch.tensor(output, dtype=torch.float).permute(1,0)\n",
    "index = torch.randperm(ntrain)\n",
    "train_index = index[:ntrain]\n",
    "x_train = input[train_index]\n",
    "y_train = output[train_index]\n",
    "x_train = x_train.reshape(ntrain, s, 2)\n",
    "train_loader = torch.utils.data.DataLoader(torch.utils.data.TensorDataset(x_train, y_train), batch_size=batch_size)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    ################################################################\n",
    "    # training and evaluation\n",
    "    ################################################################\n",
    "    \n",
    "    padding=100\n",
    "    input_channel=2\n",
    "    output_np=s\n",
    "\n",
    "    model = FNO1d(modes, width, padding=padding, input_channel=input_channel, output_np=output_np).cuda()\n",
    "    print(count_params(model))\n",
    "\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=1e-4)\n",
    "    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=step_size, gamma=gamma)\n",
    "\n",
    "    myloss = LpLoss(size_average=False)\n",
    "    print(model.conv0.weights1)\n",
    "    print(model.conv1.weights1)\n",
    "    print(model.conv2.weights1)\n",
    "    print(model.conv3.weights1)\n",
    "    print(model.conv4.weights1)\n",
    "    torch_x = 0\n",
    "    torch_y = 0\n",
    "    torch_out = 0\n",
    "    torch_loss = 0\n",
    "    for ep in range(epochs):\n",
    "        model.train()\n",
    "        t1 = default_timer()\n",
    "        train_l2 = 0\n",
    "        for x, y in train_loader:\n",
    "            x, y = x.cuda(), y.cuda()\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            out = torch.exp(model(x))\n",
    "            print(\"+++++++++++++++++++++++++++++++++++++++++++++++++++++\",out)\n",
    "            print(\"-------------------------------------------------\",y)\n",
    "\n",
    "            torch_out = out.view(batch_size, -1)\n",
    "            torch_y = y.view(batch_size, -1)\n",
    "            torch_x = x\n",
    "            loss = myloss(torch_out, torch_y)\n",
    "\n",
    "            print(\"========================================\",loss)\n",
    "            loss.backward()\n",
    "\n",
    "            optimizer.step()\n",
    "            train_l2 += loss.item()\n",
    "            torch_loss = loss.item()\n",
    "\n",
    "        scheduler.step()\n",
    "    torch_x = torch_x.cpu().numpy()\n",
    "    torch_y = torch_y.numpy()\n",
    "    torch_out = torch_out.detach().numpy()\n",
    "    torch_loss = torch_loss().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import paddle\n",
    "paddle_x = paddle.to_tensor(torch_x)\n",
    "paddle_y = paddle.to_tensor(torch_y)\n",
    "paddle_out = paddle.to_tensor(torch_out)\n",
    "paddle_loss = paddle.to_tensor(torch_loss)\n",
    "\n",
    "from catheter_copy import FNO1d\n",
    "model = FNO1d(modes, width, padding, input_channel=input_channel, output_np=output_np)\n",
    "\n",
    "print(model(paddle_x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import paddle\n",
    "from paddle.io import DataLoader, TensorDataset\n",
    "\n",
    "inputX = inputX_raw[:, 0::3]\n",
    "inputY = inputY_raw[:, 0::3]\n",
    "inputPara = inputPara_raw[:, 0::3]\n",
    "output = (output_raw[:, 0::3] + output_raw[:, 1::3] + output_raw[:, 2::3])/ 3.0\n",
    "intputX = paddle.to_tensor(inputX, dtype='float32').transpose([1,0])\n",
    "intputY = paddle.to_tensor(inputY, dtype='float32').transpose([1,0])\n",
    "\n",
    "# tensor1 = paddle.randn([1000, 2001], dtype='float32')  # 使用randn生成随机数据作为示例\n",
    "# tensor2 = paddle.randn([1000, 2001], dtype='float32')  # 同样生成随机数据\n",
    "# tensor1 = intputX\n",
    "# tensor2 = intputY\n",
    "\n",
    "input = paddle.stack([intputX, intputY], axis=2)\n",
    "# input = paddle.stack([inputX, inputY], axis=2)\n",
    "output = paddle.to_tensor(output, dtype='float32').transpose([1,0])\n",
    "index = paddle.randperm(ntrain)\n",
    "train_index = index[:ntrain]\n",
    "x_train = paddle.index_select(input, train_index)\n",
    "y_train = paddle.index_select(output, train_index)\n",
    "x_train = x_train.reshape([ntrain, s, 2])\n",
    "train_loader = DataLoader(TensorDataset([x_train, y_train]), batch_size=batch_size)#, shuffle=True)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    ################################################################\n",
    "    # training and evaluation\n",
    "    ################################################################\n",
    "    \n",
    "    padding=100\n",
    "    input_channel=2\n",
    "    output_np=s\n",
    "\n",
    "    from catheter_copy import FNO1d\n",
    "    model = FNO1d(modes, width, padding, input_channel=input_channel, output_np=output_np)\n",
    "    # print(count_params(model))\n",
    "    print(model)\n",
    "\n",
    "    optimizer = paddle.optimizer.Adam(parameters=model.parameters(),learning_rate=learning_rate, weight_decay=1e-4)\n",
    "    scheduler = paddle.optimizer.lr.StepDecay(learning_rate=optimizer.get_lr(), step_size=step_size, gamma=gamma)\n",
    "    optimizer.set_lr_scheduler(scheduler)\n",
    "\n",
    "    from utilities3_copy import *\n",
    "    myloss = LpLoss(size_average=False)\n",
    "    for ep in range(epochs):\n",
    "        model.train()\n",
    "        t1 = default_timer()\n",
    "        train_l2 = 0\n",
    "\n",
    "        for batch_id, (x, y) in enumerate(train_loader()):\n",
    "\n",
    "            out = paddle.exp(model(x))\n",
    "            \n",
    "            loss = myloss(out.view([batch_size, -1]), y.view([batch_size, -1]))\n",
    "            print('###################################################', loss.item())\n",
    "              \n",
    "            loss.backward(retain_graph=True)\n",
    "\n",
    "            optimizer.step()\n",
    "            # 梯度清零\n",
    "            optimizer.clear_grad()\n",
    "            train_l2 += loss.item()\n",
    "        # print('-------------------------------------------------', train_l2)\n",
    "        # print(model.conv4.weights1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorchAnd310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
